---
title: 大数据挖掘与数据分析笔记
date: 2024-05-11 21:46:12
description: 这是大数据挖掘与分析的期末整理复习笔记
tags:
  -期末
  -复习
  -数据分析
---

# 一、什么是数据挖掘

数据挖掘就是从数据中隐含的知识发现商业价值

# 二、为什么要数据挖掘

- 海量数据
- 维度众多
- 问题复杂

# 三、数据挖掘有什么用

## (一)分类问题

## (二) 聚类问题

## (三) 回归问题

## (四) 关联问题

# 四、怎么数据挖掘

## (一) 业务理解和数据理解(Business Understanding and Data Understanding)

理解你的数据挖掘要解决什么业务问题

必须从==商业或者业务==角度去了解项目的要求和最终的目的

- 资源
- 局限
- 设想
- 风险
- 意外

### 1. 业务背景与目标

### 2. 把握数据

#### (1) 是否有数据

是否有这样一个数据集来支持你做这样一个模型，来完成这样一个需求，来回答业务问题

#### (2) 有多少数据

数量的不同会影响处理方式

#### (3) 是什么样的数据

考虑这些维度是否可以支持完成业务需求，是否与所提出的问题有关系

#### (4) 标签

比如监督学习任务，每条数据都需要有结果的标注，这也是模型或者算法要学习的结果

## (二) 数据理解(Data Understanding)

在业务理解的基础上，对掌握的数据要有一个清晰、明确的认识

## (三) 数据准备 (Data Preparation)

**数据准备**是基于原始数据，去构建数据挖掘所需的数据集的所有工作

- 数据收集
- 数据清晰
- 数据补全
- 数据整合
- 数据转换
- 特征提取

### 1. 准备数据

如何处理出完整，干净的数据

### 2. 找到数据

每个项目需要什么数据，并从哪里获取

- 关系型数据库：MySQL
- 大数据Hbase,HIVE
- 搜索引擎数据库ES
- 内存数据库Redis
- 图数据库NEO4j,JanusGraph

### 3. 数据探索

把数据变多，升维

### 4. 数据清洗

#### (1) 缺失值的处理

一条新闻可能只有正文没有标题，发布地点，发布时间等任意数据

分析数据缺失的原因以及数据缺失的影响范围

$缺失值的处理\begin{cases}删掉有缺失值的数据\\补充缺失值\\不做处理\end{cases}$

#### (2) 异常值的处理

**异常值:**与样本空间中绝大多数数据分布差距过大的数据

- 错误的情况:比如医院录入病人病历的时候,忘了给数字输入小数点
- 正常的情况:在平均充值为100元的游戏中,有人充了100万元

#### (3) 数据偏差的处理

- 数据本身的错误:对数据进行修正,或者直接丢弃
- 数据是正确的:根据业务需求进行处理

数据偏差可能导致后面训练的模型过拟合或者欠拟合

#### (4) 数据标准化

#### (5) 特征选择

尽可能留下==较少的==数据维度

## (四) 构建模型(Modeling)

**构建模型**也叫做训练模型，重点解决技术方面的问题

选用各种各样的算法模型来处理数据，让模型学习数据的规律，并产出模型

### 1. 构建训练集与测试集

- 留出法:直接把整个数据集划分为两个互斥的部分,使得训练集和测试集互不干扰
- 交叉验证法:先把数据集划分成n个小的数据集,每次使用n-1个数据集作为训练集,剩下的作为测试集进行n次训练
- 自助法: 通过重复抽样构建数据集,通常在小数据集的情况下非常适用

### 2. 数据建模:该如何选择一个适合需求的算法

### 3. 分类问题

==分类是有监督的学习过程==

首先要有一批已经有标签结果的数据

常见算法:

- 最近邻算法(K-NearrestNeighbor,KNN)
  - 原理:找到K个与新数据最近的样本,取样本中最多的一个类别作为新数据的类别
  - 优点:
    - 简单易实现
    - 对于边界不规则的数据效果好
  - 缺点:
    - 只适合小数据集
    - 数据不平衡效果不好
    - 必须要做数据标准化
    - 不适合特征维度太多的数据
  - 关于K的选取:K值的选取会影响到模型的效果
    - K越小,越容易过拟合
    - K越大，越容易欠拟合
    - 一般把K从1开始，依次增大
    - 


- 决策树

  - 决策树使用==信息增益==的方法来衡量一个特征和特征之间的重要性
  - 优点：

    - 非常直观，可解释性强
    - 预测速度比较快
    - 可以处理离散值，连续值，缺失值

  - 缺点：

    - 容易过拟合
    - 需要处理样本不均衡问题
    - 样本的变化会引发树结构的巨变

  - 解决办法：

    - 预剪枝
    - 后剪枝
- 随机森林

  - 使用bagging方案构建了多棵决策树，然后对所有树的结果来进行平均计算以获取最终的结果
  - GBDT构建的多棵树之间是有联系的，每个分类器是在上一轮分类器的残差基础上进行训练
  - XGBoost 优化了GBDT 里面求解的过程，并加入了很多工程上的优化项目
- 朴素贝叶斯

  - 优点：逻辑清晰简单，易于实现，适合大规模数据
    - 运算开销小
    - 预测过程快
    - 对于噪声和无关属性比较健壮
  - 缺点：具体应用时要考虑特征之间的相互独立性，再决定是否要使用该算法
  - 改进：
    - 半朴素贝叶斯ODE：建立一些属性间的联系，假定属性有一定的相关性，从而产生的算法
    - AODE：在ODE的基础上，使用bagging集成学习的思路，训练多个模型
- 支持向量机（SVM）

  - 假设找到一条线可以分隔红豆和绿豆
  - 红豆中距离这条线最近的几个样本点被称为支持向量
  - 这些点到这条线的距离称为间隔




#### (1) 二分类

要回答的问题只有"是"或"否"

#### (2) 多分类

在二分类的基础上,将标签可选范围扩大

#### (3) 多标签分类

多标签分类的下一条数据可以被标注上多个标签

### 4. 聚类问题

==聚类是无监督的学习过程==

- **互斥**:小组和小组之间是没有交集的,一个用户只存在于一个小组中
- **相交**:小组和小组之间有交集,一条数据可能既存在于A组,也存在于B组
- **层次:**一个大组还可以细分成若干个小组,比如高消费用户还可以分为累计高消费和单次高消费
- **模糊:**一个用户并不绝对属于某个小组,只能用概率表示他和某个小组的关系

方法:

- 基于划分的聚类
- 基于密度的聚类
- 基于层级的聚类
- 基于模型的聚类

### 5. 回归问题

**回归Regression(消退,回复)**

|      | 分类         | 回归         |
| ---- | ------------ | ------------ |
| 输出 | 离散数据     | 连续数据     |
| 目的 | 寻找决策边界 | 找到最优拟合 |

### 6. 关联问题

==关联无监督学习==

### 7. 模型集成

合成多个模型来提升整体的效果

方式

- Bagging(装袋法)
- Boosting(增强法)
- Stacking(堆叠法)

## (五) 评估模型(Evaluation)

### 1. 评估指标

#### (1) 混淆矩阵与准确率指标

**准确率相关指标**:可以直接反映一个模型对于样本数据的学习情况,是一种标准化检验

| 样本1000份  | 模型检测:是 | 模型检测:否 |
| ----------- | ----------- | ----------- |
| 人工标注:是 | 745(TP)     | 55(FN)      |
| 人工标注:否 | 25(FP)      | 175(TN)     |

混淆矩阵中包含四种数值

- 真阳性(True Positive, TP):小猪图被判定为小猪图
- FP真阴性(True Negative, TN): 不是小猪图被判定为不是小猪图
- 假阳性(False Positive, FP):不是小猪图被判定为小猪图
- 假阴性(False Negative, FN): 小猪图被判定为不是小猪图

**准确率(Accuracy):**所有预测正确的占全部样本的概率

$公式:Accuracy=\frac{TP+TN}{TP+TN+FP+FN}$

**精确率(Precision):**预测正确的结果占所有预测成"是"的概率

$公式:Accuracy=\frac{TP}{TP+FP}$

**召回率(Recall):**该类别下预测正确的结果占该类别所有数据的概率

$公式:Accuracy=\frac{TP}{TP+FN}$

**F值(F Score):**准确率和召回率的调和平均值

$公式: 2*\frac{Accuracy*Recall}{Accuracy+Recall}$

**ROC曲线和AUC曲线**:构建了很多组混淆矩阵

真正利率: TP/(TP+FN)

假正利率: FP/(FP+TN)

#### (2). 业务指标

#### (3). 泛化能力

- 过拟合:训练集上表现良好,测试集或者验证集表现不佳
- 欠拟合: 在训练集和测试集上的表现都不好

#### (4). 模型速度

#### (5). 鲁棒性

#### (6). 可解释性

### 2.评估数据的处理

- 随机抽样: 把数据分成训练集和测试集,使用测试集对模型进行测试,得到各种准确率指标
- 随机多次抽样: 在随机抽样的基础上,进行n次随机抽样,得到n组测试集,使用这n组的平均值作为最终结果
- 交叉验证:需要选择多个模型,把原始的数据分为k份,每次选取其中的一份作为测试集,其他的作为训练集训练一个模型,计算这k个模型结果作为整体获得的准确率
- 自助法:随机有放回地抽取样本,构建一个训练集,对比原始样本集和该训练集,把训练集中未出现的内容整理成为测试集,重复这个过程k次,构建k个模型

## (六) 模型部署(Deployment)

